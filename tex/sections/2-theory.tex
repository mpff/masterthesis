As a starting point, it is important to establish a notational and mathematical framework for the treatment of planar shapes.
While the restriction to the 2D case might seem a major one, it still covers all shape data extracted from e.g.\ imagery and is therefore very applicable in practice.
The outline of a 2D object may be naturally represented by a planar curves $\beta : [0,1] \rightarrow \mathbb{R}^2$ with $\beta(t) = (x(t),\, y(t))^T$, where $x(t)$ and $y(t)$ are the scalar-valued \textit{coordinate functions}.
Calculations in two dimensions, and in particular the derivation of the full Procrustes mean, are greatly simplified by using complex notation.
Going forward, we will therefore identify $\mathbb{R}^2$ with $\mathbb{C}$ and always use complex notation when representing a planar curve
$$\beta : [0,1] \rightarrow \mathbb{C}, \quad \beta(t) = x(t) + i\, y(t).$$
For reasons that will be discussed in Section \ref{theo:dist}, we furthermore assume the curves to be absolutely continuous or $\beta \in \mathcal{AC}([0,1], \mathbb{C})$.
All considerations will be restricted to the case of open curves, with possible extensions to closed curves $\beta \in \mathcal{AC}(\mathbb{S}^1, \mathbb{C})$ discussed in Section \ref{app:closed} of the appendix.


\section{Equivalence Classes and Shape Invariance}
\label{theo:inv}
As mentioned in the introduction, shape is usually defined by its invariance under the transformations of scaling, translation, and rotation.
When considering the shape of curves, we additionally have to take into account invariance with respect to re-parametrisation.
This can be seen, by noting that the curves $\beta(t)$ and $\beta(\gamma(t))$, with some re-parametrisation or \textit{warping function} $\gamma : [0,1] \rightarrow [0,1]$ monotonically increasing and differentiable, have the same image and therefore represent the same geometrical object.
We can say that the actions of translation, scaling, rotation, and re-parametrisation are \textit{equivalence relations} with respect to shape, as each action leaves the shape of the curve untouched and only changes the way it is represented.
The shape of a curve can then be defined as the respective \textit{equivalence class}, i.e. the set of all possible shape preserving transformations of the curve.
As two equivalence classses are neccessarily either disjoint or identical, we can consider two curves as having the same shape, if they are elements of the same equivalence class \parencite[see][40]{SrivastavaKlassen2016}.

When defining an equivalence class, one has to first consider how the individual transformations act on a planar curve with complex representation $\beta : [0,1] \rightarrow \mathbb{C}$.
This is usually done using the notion of \textit{group actions} and \textit{product groups}, with the later desciribing multiple transformations acting at once.
A brief introduction to group actions may be found in \cite[Chap.\ 3]{SrivastavaKlassen2016}.
\begin{itemize}[leftmargin=0.75cm]
  \item[1.]
    The \emph{translation} group $\mathbb{C}$ acts on $\beta$ by $(\xi, \beta) \xmapsto{\text{Trl}} \beta + \xi$, for any $\xi \in \mathbb{C}$.
    We can consider two curves as equivalent with respect to translation $\beta_1 \overset{\text{Trl}}{\backsim} \beta_2$, if there exists a complex scalar $\widetilde\xi \in \mathbb{C}$ so that $\beta_1 = \beta_2  + \widetilde\xi$.
    Then, for some function $\beta$, the related equivalence class with respect to translation is given by $[\beta]_{\text{Trl}} = \{\beta + \xi\, |\, \xi \in \mathbb{C}\}$.
  \item[2.] 
    The \emph{scaling} group $\mathbb{R}^+$ acts on $\beta$ by $(\lambda, \beta) \xmapsto{\text{Scl}} \lambda \beta$, for any $\lambda \in \mathbb{R}^+$.
    We define $\beta_1 \overset{\text{Scl}}{\backsim} \beta_2$, if there exists a scalar $\widetilde\lambda \in \mathbb{R}^+$ so that $\beta_1 = \widetilde\lambda \beta_2$.
    An equivalence class is $[\beta]_{\text{Scl}} = \{\lambda\beta\,|\, \lambda \in \mathbb{R}^+\}$.
  \item[3.] 
    The \emph{rotation} group $[0,2\pi]$ acts on $\beta$ by $(\theta, \beta) \xmapsto{\text{Rot}}  e^{i\theta} \beta$, for any $\theta \in [0,2\pi]$.
    We define $\beta_1 \overset{\text{Rot}}{\backsim} \beta_2$, if there exists a $\widetilde\theta \in [0,2\pi]$ with $\beta_1 = e^{i\widetilde\theta} \beta_2$.
    An equivalence class is $[\beta]_{\text{Rot}} = \{e^{i\theta}\beta\,|\, \theta \in [0,2\pi]\}$.
  \item[4.] 
    The \emph{warping} group $\Gamma$ acts on $\beta$ by $(\gamma,\beta) \xmapsto{\text{Wrp}} \beta \circ \gamma$, for any $\gamma \in \Gamma$ with $\Gamma$ being the set of monotonically increasing and differentiable warping functions.
    We define $\beta_1 \overset{\text{Wrp}}{\backsim} \beta_2$, if there exists a warping function $\widetilde\gamma \in \Gamma$ with $\beta_1 = \beta_2 \circ \widetilde\gamma$.
    An equivalence class is $[\beta]_{\text{Wrp}} = \{\beta \circ \gamma\,|\, \gamma \in \Gamma\}$.
\end{itemize}
In a next step, we can consider how these transformations act in concert and whether they \textit{commute}, that is, whether the order of applying the transformations changes outcomes.
Consider for example the actions of the rotation and scaling product group $\mathbb{R}^+ \times [0,2\pi]$ given by $((\lambda, \theta), \beta) \xmapsto{\text{Scl} + \text{Rot}} \lambda e^{i\theta} \beta$.
These clearly commute, because the order of applying rotation or scaling do not make a difference, as $\lambda(e^{i\theta}\beta) = e^{i\theta}(\lambda\beta)$.
However, the joint actions of scaling and translation do not commute, as $\lambda(\beta + \xi) \neq \lambda\beta + \xi$, with the same holding for the joint action of rotation and translation.
As the order of translating and rotating or scaling matters, one usually takes the translation to act on the already scaled and rotated curve.
The joint action defined using this ordering is usually called an \textit{Euclidean similarity transformation}.

\begin{definition}[Euclidean similarity transformation] 
  We define an \emph{Euclidean similarity transformation} of a curve $\beta : [0,1] \rightarrow \mathbb{C}$ as the joint action of scaling, rotation, and translation by 
  $$((\xi, \lambda, \theta), \beta) \mapsto \lambda e^{i\theta} \beta + \xi,$$
  with $\xi \in \mathbb{C}$, $\lambda \in \mathbb{R}^+$, and $\theta \in [0,2\pi]$ \parencite[see][62]{DrydenMardia2016}.
\end{definition}

\noindent With respect to the action of re-parametrization, we can note that it necessarily commutes with all Euclidean similarity transformations, as those only act on the image of $\beta$, while the former only acts on the parametrization.
Putting everything together, we can finally give a formal definition of the shape of a planar curve.

\begin{definition}[Shape]
  The \emph{shape} of an absolutely continous planar curve $\beta \in \mathcal{AC}([0,1], \mathbb{C})$ is given by its equivalence class with respect to all Euclidean similarity transformations and re-parametrisations
  $$ [\beta] = \left\{\lambda e^{i\theta}(\beta \circ \gamma) + \xi\,|\, \xi \in \mathbb{C},\, \lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi],\, \gamma \in \Gamma\right\}. $$
  The \emph{shape space} is then given by the corresponding quotient space 
  $$\mathcal{AC}([0,1], \mathbb{C}) \big/ \Gamma \times \mathbb{C} \rtimes \left( \mathbb{R}^+ \times [0,2\pi] \right) = \left\{[\beta]\,|\,\beta \in \mathbb{C}^{[0,1]}\right\},$$
  where the symbol \enquote{$\rtimes$} denotes a semi-direct product, i.e. the translation group acts \enquote{after} scaling and rotation. 
  \textbf{[This is probably not super clear.]}
\end{definition}


\section{The Elastic Full Procrustes Distance for Planar Curves}
\label{theo:dist}
Let us now turn to the calculatation of distances between the shapes of curves.
As shapes are represented by certain equivalence classes, and are therefore elements of a non-Euclidean quotient space, calculating their distance is not straight-forward.
A common approach is to \enquote{project} the distance calculation in shape space down into the underlying functional space.
For example, consider $\beta_1$, $\beta_2 \in \mathbb{L}^2([0,1],\, \mathbb{C})$ with $[\beta_1]$, $[\beta_2]$ their equivalence classes with respect to all shape-preserving transformations.
We might want to calculate their shape-distance as the minimal $\mathbb{L}^2$-distance, when optimizing over all elements of their respective equivalence classes:
$$ d([\beta_1], [\beta_2]) = \inf_{\widetilde \beta_1 \in [\beta_1],\,\widetilde \beta_2 \in [\beta_2]} d_{\mathbb{L}^2}(\widetilde \beta_1, \widetilde \beta_2) = \inf_{\widetilde\beta_1 \in [\beta_1],\, \widetilde\beta_2 \in [\beta_2]} \norm{ \widetilde\beta_1 - \widetilde\beta_2}_{\mathbb{L}^2}.$$
Which is equivalent to optimizing over all shape-preserving transformations:
\begin{align*}
  d([\beta_1], [\beta_2]) = \inf_{\lambda_{1,2} \in \mathbb{R}^+,\,\theta_{1,2} \in [0,2\pi],\, \xi_{1,2} \in \mathbb{C},\, \gamma_{1,2} \in \Gamma}\,\, & \bigg\lVert \,\lambda_1 e^{i\theta_1}(\beta_1 \circ \gamma_1) + \xi_1 \\
  &\quad - \left(\lambda_2 e^{i\theta_2}(\beta_2 \circ \gamma_2) + \xi_2 \right) \bigg\rVert_{\mathbb{L}^2}.
\end{align*}
However, this approach runs into problems, when considering whether all transformations act by isometries on this distance, i.e.\ whether equally changing the translation, rotation, scaling or re-parametrization of both curves affects their distance. 

As it turns out, neither re-parametrization nor scaling are distance preserving when using the $\mathbb{L}^2$-distance:
For two equally re-parameterized curves $\widetilde\beta_{1,2} = \beta_{1,2} \circ \gamma$, their squared $\mathbb{L}^2$-distance is given by $\norm{\beta_1 \circ \gamma - \beta_2 \circ \gamma}^2 = \int_0^1 \norm{\beta_1(\gamma(t)) - \beta_2(\gamma(t))}^2 dt = \int_0^1 \norm{\beta_1(s) - \beta_2(s)}^2 \frac{1}{\dot\gamma(\gamma^{-1}(s))} ds$ with $s = \gamma(t)$.
It follows that $\norm{\widetilde\beta_1 - \widetilde\beta_2} \neq \norm{\beta_1 - \beta_2}$, as in general $\dot\gamma(\gamma^{-1}(s)) \neq 1$.
Likewise, it holds for equal re-scaling that $\norm{\lambda \beta_1 - \lambda \beta_2} = \abs\lambda\, \norm{\beta_1 - \beta_2} \neq \norm{\beta_1 - \beta_2}$.
This has the consequence that the above optimization problem might simply be solved by $\lambda_1, \lambda_2 \rightarrow 0$, leading to $d([\beta_1], [\beta_2]) \rightarrow 0$ for any two curves $\beta_1$, $\beta_2$.
Furthermore, optimizing over re-parametrization using the $\mathbb{L}^2$-distance has problems relating to the so called \textit{pinching effect} and \textit{inverse-inconsistency}, where the later means that aligning the parametrisation of one curve to another by $\inf_{\gamma \in \Gamma} \norm{\beta_1 - \beta_2 \circ \gamma}$ may yield different results than $\inf_{\gamma \in \Gamma} \norm{\beta_2 - \beta_1 \circ \gamma}$ \parencite[see][88]{SrivastavaKlassen2016}.

A solution proposed in \cite{SrivastavaEtAl2011} is to ditch the $\mathbb{L}^2$-metric in favor of an \textit{elastic metric}, which is isometric with respect to re-parametrization.
Calculation of this metric, the Fisher-Rao Riemannian metric \parencite{Rao1945}, can be greatly simplified by using the \textit{square-root-velocity} (SRV) framework, as the Fisher-Rao metric of two curves can be equivalently calculated as the $\mathbb{L}^2$-distance of their respective SRV curves.

\begin{definition}[SRV function of a planar curve]
  The \emph{SRV function} (SRVF) of an absolutely continuous planar curve $\beta \in \mathcal{AC}([0,1],\,\mathbb{C})$ is given by
  $$ \quad q(t) = \frac{\dot{\beta}(t)}{\sqrt{|| \dot{\beta}(t) ||}} \quad \text{for} \,\, \dot{\beta}(t) \neq 0, \,\, \text{with} \,\, q \in \mathbb{L}^2([0,1], \mathbb{C}),$$
  where the original curve $\beta$ can be re-constructed from its SRVF, up to translation, by $\beta(t) = \beta(0) + \int_0^t q(s) || q(s) || ds$.
\end{definition}

\noindent As this representation makes use of derivatives, any curve $\beta$ that has a SRVF must fulfill some kind of differentiability constraint.
Here it is enough to consider only curves that are absolutely continuous $\beta \in \mathcal{AC}([0,1],\, \mathbb{C})$.
In particular, this means that the original curves do not have to be smooth but might also be piecewise linear \parencite[see][91]{SrivastavaKlassen2016}.
The SRVFs are considered elements of a Hilbert space, which is given by $\mathcal{L}^2([0,1],\,\mathbb{C})$ equipped with the complex inner product $\langle \cdot, \cdot \rangle$ and corresponding norm $||\cdot||$.
The complex inner product of $q,q' \in \mathcal{L}^2([0,1],\,\mathbb{C})$ is defined as
$$ \langle q, q' \rangle = \int_0^1 \overline{q(t)} q'(t) dt \,, $$
with $\overline{z} = \operatorname{Re}(z) - i \operatorname{Im}(z)$ denoting the complex conjugate.

As we can always recover the original curve up to translation, the SRV representation holds all relevant information about the shape of a curve.
Furthermore, because of the use of derivatives, the SRV representation is invariant under changes in translation of the original curve.
As a consequences, all shape-preserving transformations commute on SRV level.

\begin{lemma}
  The actions of the translation, scaling, rotation, and re-parametrization groups commute on SRV level.
\begin{proof} The SRVF $\widetilde q(t)$ of  $\widetilde\beta(t) = \lambda e^{i\theta}\beta\left(\gamma(t)\right) + \xi$ is given by
$$ \widetilde q (t) 
  = \frac{\lambda e^{i\theta} \dot\beta\left(\gamma(t)\right) \dot\gamma(t)}{\sqrt{||\lambda e^{i\theta} \dot\beta\left(\gamma(t)\right) \dot\gamma(t)||}} 
  = \sqrt{\lambda} e^{i\theta} \frac{\dot\beta\left(\gamma(t)\right)}{\sqrt{||\dot\beta\left(\gamma(t)\right)||}} \sqrt{\dot\gamma(t)} 
  = \sqrt\lambda e^{i\theta} \left( q \circ \gamma \right) \sqrt{\dot\gamma(t)}.$$
The result is irrespective of the order of applying the transformations.
\end{proof}
\end{lemma}
\begin{remark}
  It follows, that the individual transformations translate to SRV level by 
  $$\text{i.)} \,\,(\xi, q) \xmapsto{\text{Trl}} q,\quad 
    \text{ii.)} \,\, (\lambda, q) \xmapsto{\text{Scl}} \sqrt\lambda q,\quad
    \text{iii.)} \,\, (\theta, q) \xmapsto{\text{Rot}} e^{i\theta} q,\quad
    \text{iv.)} \,\, (\gamma, q) \xmapsto{\text{Wrp}} (q \circ \gamma) \sqrt{\dot\gamma}.$$
\end{remark}
\noindent We can use this to identify the shape of a curve as the equivalence class of its respective SRVF modulo scaling, rotation, and warping, where we do not need to consider translation anymore.
\begin{definition}[Shape (SRV)]
  The \emph{shape} $[\beta]$ of an absolutely continuous, planar curve $\beta \in \mathcal{AC}([0,1],\, \mathbb{C})$ can be equivalently represented by the equivalence class $[q]$ of its SRV representation $q = \frac{\dot\beta(t)}{\sqrt{|\dot\beta(t)|}} \in \mathbb{L}^2([0,1],\,\mathbb{C})$ modulo scaling, rotation and re-parametrization
  $$[q] = \left\{\sqrt\lambda e^{i\theta}(q \circ \gamma) \sqrt{\dot\gamma(t)} \,|\, \lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi],\, \gamma
  \in \Gamma\right\}.$$
\end{definition}
\noindent Going forward, we will now work in the SRV framework and use the elastic metric for distance calculations between shapes.
This means, instead of optimizing over the $\mathbb{L}^2$ distance between the original curves, we optimize over the $\mathbb{L}^2$ distance between their respective SRVFs.
For two absolutely continuous curves $\beta_1, \beta_2 \in \mathcal{AC}([0,1],\,\mathbb{C})$ with respective SRV curves $q_1, q_2 \in \mathbb{L}^2([0,1],\,\mathbb{C})$ we might define the \textit{elastic} distance between their shapes as
$$d([\beta_1], [\beta_2]) = 
  \inf_{\widetilde q_1 \in [q_1],\,\widetilde q_2 \in [q_2]} \norm{ \widetilde q_1 - \widetilde q_2 }_{\mathbb{L}^2}$$
or when equivalently optimizing over all possible transformations as
$$d([\beta_1], [\beta_2]) = 
  \inf_{\lambda_{1,2} \in \mathbb{R}^+,\,\theta_{1,2} \in [0,2\pi],\, \gamma_{1,2} \in \Gamma} \norm{ \sqrt{\lambda_1} e^{i\theta_1}(q_1 \circ \gamma_1) \sqrt{\dot\gamma_1} - \sqrt{\lambda_2} e^{i\theta_2}(q_2 \circ \gamma_2) \sqrt{\dot\gamma_2}}_{\mathbb{L}^2}\,.$$
We can simplify the optimization, by considering that both rotation and warping act by isometries on the elastic metric, which means in practice it is enough to optimize over the rotation and warping of only one of the curves.
For warping, we can reformulate the optimisation as a problem over the relative parametrisation between the curves, as $\inf_{\gamma_1,\gamma_2 \in \Gamma} \norm{q_1 \circ \gamma_1 - q_2 \circ \gamma_2} = \inf_{\gamma_1,\gamma_2 \in \Gamma} \norm{q_1 - (q_2 \circ (\gamma_2 \circ \gamma_1^{-1})) \sqrt{\dot{(\gamma_2 \circ \gamma_1^{-1})}}}= \,\,\,\,\inf_{\gamma \in \Gamma} \,\,\,\, \norm{q_1 - (q_2 \circ \gamma) \sqrt{\dot\gamma}}$.
And smilarly for rotation, we can optimize over the relative rotation between both curves, as
$\inf_{\theta_1,\theta_2 \in [0,2\pi]} \norm{e^{i\theta_1}q_1 - e^{i\theta_2}q_2} = \inf_{\theta_1, \theta_2 \in [0,2\pi]} \norm{q_1 - e^{i(\theta_2 - \theta_1)}q_2} ) = \inf_{\theta \in [0,2\pi]} \norm{q_1 - e^{i\theta}q_2}$.
Taken together these lead to
$$d([\beta_1], [\beta_2]) = 
  \inf_{\lambda_{1,2} \in \mathbb{R}^+,\,\theta \in [0,2\pi],\, \gamma \in \Gamma} \norm{ \sqrt{\lambda_1}q_1 - \sqrt{\lambda_2} e^{i\theta}(q_2 \circ \gamma) \sqrt{\dot\gamma}}\,,$$
which, however, still has the problem of not being isometric with respect to scaling.

A possible solution, mirroring the definition of the \emph{full Procrustes distance} for landmark data, is to work with the normalized representations $z = \frac{q}{\norm q}$, while only aligning the scaling of one of the curves.
This leads to a distance that is isometric with respect to scaling, as for $\widetilde{q}_{1,2} = \lambda q_{1,2}$ it holds that $\norm{\widetilde z_1 - \widetilde z_2} = \norm{ \frac{\lambda q_1}{\norm{\lambda q_1}} - \frac{\lambda q_2}{\norm{\lambda q_2}}} \overset{\lambda \in \mathbb{R}^+}{=} \norm{z_1 - z_2}$, while also being inverse consistent, as $\inf_{\lambda \in \mathbb{R}^+} \norm{z_1 - \lambda z_2}^2 = \inf_{\lambda \in \mathbb{R}^+}\,\norm{z_1}^2 + \lambda^2 \norm{z_2}^2 - \lambda (\langle z_1, z_2 \rangle + \langle z_2, z_1 \rangle) = 1 + \lambda^2 - \lambda (\langle z_1, z_2 \rangle + \langle z_2, z_1 \rangle) = \inf_{\lambda \in \mathbb{R}^+} \norm{z_2 - \lambda z_1}^2$.
We can finally take everything together, leading to a definition for the \emph{elastic full Procrustes distance}.
\begin{definition}[Elastic full Procrustes distance]
  \label{def:dist}
  The \emph{elastic full Procrustes distance} between the shapes $[\beta_1]$, $[\beta_2]$ of two continuously differentiable planar curves $\beta_1$, $\beta_2 \in \mathcal{AC}([0,1],\mathbb{C})$  is given by 
    $$d_{EF}([\beta_1], [\beta_2]) = \inf_{\lambda \in \mathbb{R}^+,\, \theta \in
    [0,2\pi],\, \gamma \in \Gamma} \norm{z_1 - \lambda e^{i\theta} (z_2 \circ \gamma) \sqrt{\dot\gamma}}\, $$
    with normalized SRV representation $z_{1,2} = \frac{q_{1,2}}{\norm{q_{1,2}}} \in \mathbb{L}^2([0,1], \mathbb{C})$.
\end{definition}
\begin{remark}
  If the original curve $\beta$ is of unit length $L[\beta] = \int_0^1 \abs{\dot\beta(t)}dt = 1$, the SRV curve $q = \frac{\dot\beta}{\norm{\dot\beta}}$ will be automatically normalized, as $ \norm{q} = \sqrt{ \int_0^1 |q(t)|^2 \, dt} = \sqrt{\int_0^1 |\dot{\beta}(t)| \, dt} = 1$.
\end{remark}

First, we consider the optimisation over rotation and scaling.
For a fixed $\gamma \in \Gamma$, the optimisation problem in Definition \ref{def:dist} mirrors the optimisation problem of the full Procrustes distance for landmark data, where an explicit solution is known in the planar case \parencite[see][Chapter~8]{DrydenMardia2016}.

\begin{lemma}
  The optimisation problem in Definition \ref{def:dist} can be reduced to
  $$ d_{EF}([\beta_1],[\beta_2]) = \inf_{\gamma \in \Gamma} \sqrt{ 1 - \langle z_1, (z_2 \circ \gamma) \sqrt{\dot\gamma} \rangle \langle (z_2 \circ \gamma) \sqrt{\dot\gamma}, z_1 \rangle }$$
  \begin{proof}
  See \ref{app:deriv-full-proc-dist} in the appendix.
  \end{proof}
\end{lemma}


\newpage
\section{The Elastic Full Procrustes Mean for Planar Curves}

\begin{definition}[Full Procrustes mean]
    The \emph{full Procrustes mean} shape for a sample of landmark
    configurations $X_i$ ($i = 1,\dots,n$) is then given by the equivalence
    class [$\hat\mu_F$] of a landmark configuration that minimizes the sum of
    squared full Procrustes distances
    $$\hat{\mu}_F = \arginf_{\mu} \sum_{i=1}^n d_F([\mu], [X_i])^2, $$
    where $\mu$ is assumed centered and normalized
    \parencites[see][71,114]{DrydenMardia2016}.
\end{definition}

Let $\beta$ be a continuous planar curve.
It can be represented in a parameterized form in $\mathbb{R}^2$ as
$$ \beta : [0,1] \rightarrow \mathbb{R}^2,\quad \beta(t) = ( x(t), y(t)) \,, $$
where $x, y$ are scalar-valued \textit{coordinate functions} of $\beta$, parametrized by $t$.
We can equivalently represent a planar curve using complex numbers as
$$ \beta : [0,1] \rightarrow \mathbb{C},\quad \beta(t) = x(t) + iy(t) \,, $$
with the added benefit that complex notation often simplifies calculations in the 2D case.

For a set of planar curves $\beta_1,\dots,\beta_n : [0,1] \rightarrow \mathbb{C}$, either centered with $\langle \beta_i, \mathbb{1} \rangle$ or with no relative translation to each other, the \textit{full Procrustes mean} $\hat{\mu}$ is then defined as the curve minimizing the sum of squared \textit{full Procrustes distances} from each $\beta_i$ to an unknown unit size mean configuration $\mu$, that is
\begin{align*}
    \hat{\mu} =& \argmin_{\mu:[0,1]\rightarrow\mathbb{C}} \sum_{i=1}^n d^2_F(\mu,\beta_i)
    \quad\text{s.t.}\,\, ||\mu|| = 1 \\
    =& \argmin_{\mu:[0,1]\rightarrow\mathbb{C}} \sum_{i=1}^n 1 - \frac{\langle \mu, \beta_i \rangle \langle \beta_i, \mu \rangle}{\langle \mu, \mu \rangle \langle \beta_i, \beta_i \rangle}
    \quad\text{s.t.}\,\, ||\mu|| = 1
\end{align*}
which we can be further simplified by normalizing $\beta_i := \frac{\beta_i}{|| \beta_i ||}$ and using $\langle \mu, \mu \rangle = 1$
$$ \hat{\mu} = \argmax_{\mu:[0,1]\rightarrow\mathbb{C}} \sum_{i=1}^n \langle \mu, \beta_i \rangle \langle \beta_i, \mu \rangle \quad\text{s.t.}\,\, ||\mu|| = 1. $$
The expression for $d^2_F(\mu,\beta_i)$ in the case of planar curves is derived in appendix \ref{app:deriv-full-proc-dist}.



Consider a set of planar SRV curves $q_1,\dots,q_n : [0,1] \rightarrow \mathbb{C}$ of unit length $||q_i|| = 1$ for all $i$.
The \textit{full Procrustes mean} $\hat{\mu}$ is given by
\begin{align*}
    \hat{\mu} =& \argmax_{\mu:[0,1]\rightarrow\mathbb{C}} \sum_{i=1}^n \langle \mu, q_i \rangle \langle q_i, \mu \rangle
    \quad\text{s.t.}\,\, ||\mu|| = 1 \\
    =& \argmax_{\mu:[0,1]\rightarrow\mathbb{C}} \sum_{i=1}^n
    \int_0^1 \overline{\mu(t)} q_i(t) \, dt \int_0^1 \overline{q_i(s)} \mu(s) \, ds
    \quad\text{s.t.}\,\, ||\mu|| = 1 \\
    =& \argmax_{\mu:[0,1]\rightarrow\mathbb{C}}  \int_0^1 \int_0^1
    \overline{\mu(t)} \underbrace{\left( \sum_{i=1}^n q_i(t) \overline{q_i(s)} \right)}_{\coloneqq \, n \hat{C}(s,t)} \mu(s) \, dt ds
    \quad\text{s.t.}\,\, ||\mu|| = 1 \\
    =& \argmax_{\mu:[0,1]\rightarrow\mathbb{C}} \int_0^1
    \overline{\mu(t)} \int_0^1 \hat{C}(s,t) \mu(s) \, ds dt
    \quad\text{s.t.}\,\, ||\mu|| = 1
\end{align*}
with the solution given by the eigenfunction corresponding to the largest eigenvector of the complex empirical covariance function $\hat{C}(s,t) = n^{-1} \sum_{i=1}^n q_i(t) \overline{q_i(s})$.



