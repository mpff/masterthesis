\label{app:a}

\section{Additional Proofs and Derivations}
\label{app:a-deriv}

\subsection{Derivation of Lemma \ref{lem:2-fpdist}}
\label{app:a-deriv-fpdist}
\begin{align*}
  d_{FP}([\beta_1]_\Eucl,[\beta_2]_\Eucl)^2 
    = & \min_{\omega \in \mathbb{C}} \,\, \norm{\widetilde \beta_1 - \omega \widetilde \beta_2}^2 \\
    = & \min_{\lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi)} \norm{\widetilde \beta_1 - \lambda e^{\iu\theta} \widetilde \beta_2}^2 \\
    = & \min_{\lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi)} \langle \widetilde \beta_1 - \lambda e^{\iu\theta} \widetilde \beta_2, \widetilde \beta_1 - \lambda e^{\iu\theta} \widetilde \beta_2 \rangle \\
    = & \min_{\lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi)} \norm{\widetilde \beta_1}^2 + \lambda^2 \norm{\widetilde \beta_2}^2 - \lambda ( e^{\iu\theta} \langle \widetilde \beta_1, \widetilde \beta_2 \rangle + e^{-\iu\theta} \langle \widetilde \beta_2, \widetilde \beta_1 \rangle 
\end{align*}
Define $\langle \widetilde \beta_1, \widetilde \beta_2 \rangle = \kappa e^{\iu\phi} \in \mathbb{C}$ with $\kappa \in \mathbb{R}^+$, $\phi \in [0,2\pi)$ and use $\norm{\widetilde \beta_1} = \norm{\widetilde \beta_2} = 1$.
\begin{align*}
  d_{FP}([\beta_1]_\Eucl,[\beta_2]_\Eucl)^2 
   = &  \min_{\lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi)} 1 + \lambda^2  - \lambda ( e^{\iu\theta} \kappa e^{\iu\phi} + e^{-\iu\theta} \kappa e^{-\iu\phi} ) \\
   = &  \min_{\lambda \in \mathbb{R}^+,\, \theta \in [0,2\pi)} 1 + \lambda^2  - \lambda \kappa \left( e^{\iu(\theta + \phi)} + e^{-\iu (\theta + \phi)} \right) \\
   = &  \min_{\lambda \in \mathbb{R}^+} 1 + \lambda^2  - \max_{\theta \in [0,2\pi)} 2 \lambda \kappa \cos{(\theta + \phi)} \\
   \overset{\theta^\mathrm{opt} = -\phi}{=} & \min_{\lambda \in \mathbb{R}^+} 1 + \lambda^2  - 2 \lambda \kappa
\end{align*}
From $\frac{\partial}{\partial\lambda}\left( 1 + \lambda^2 - 2\lambda\kappa \right) = 2\lambda - 2\kappa \overset{!}{=} 0$ it follows that $\lambda^\mathrm{opt} = \kappa$.
\begin{align*}
  d_{FP}([\beta_1]_\Eucl,[\beta_2]_\Eucl)^2 
   = &  \left( 1 + \kappa^2  - 2 \kappa^2 \right) =  \left( 1 - \kappa^2 \right)
\end{align*}
\cref{lem:2-fpdist} i.) follows by considering $\kappa^2 = \abs{\langle \widetilde \beta_1, \widetilde \beta_2 \rangle}^2 = \langle \widetilde \beta_1, \widetilde \beta_2 \rangle \langle \widetilde \beta_2, \widetilde \beta_1 \rangle$.
Then
\begin{align*}
  d_{FP}([\beta_1]_\Eucl,[\beta_2]_\Eucl)
   = &  \sqrt{ 1 - \langle \widetilde \beta_1, \widetilde \beta_2 \rangle \langle \widetilde \beta_2, \widetilde \beta_1 \rangle }\,.
\end{align*}
\cref{lem:2-fpdist} ii.) follows by $\omega^\mathrm{opt} = \lambda^\mathrm{opt} e^{\iu \theta^\mathrm{opt}} = \kappa e^{-\iu\phi} = \overline{\langle \widetilde \beta_1, \widetilde \beta_2 \rangle} = \langle \widetilde \beta_2, \widetilde \beta_1 \rangle$.


\section{Shape-Smoothing Using the Estimated Covariance-Surface}
\label{app:a-smooth}
Instead of treating $\widetilde q$ as piecewise constant, we might want to smooth each curve in the mean basis $b(t)$, so that $\widetilde q \approx b(s)^\top \hat\theta$.
The optimal rotation and scaling alignment is then simply given by the scalar product 
$ \omega = \langle \widetilde q, \hat\mu_q \rangle \approx (\hat\theta)^H G \hat\theta_\mu$, where $\hat\theta_\mu$ are the estimated mean basis coefficients.
To make use of information from the other observations, we can estimate the coefficient vector $\theta$ in way that penalises deviations from the estimated mean covariance-structure $\hat\Xi$.
This may be achieved by using a ridge penalty, where we assume $\widetilde q \sim \mathcal{N}_{\mathbb{C}^k}(B \theta, \sigma^2 I_{m})$, with $B$ the $m \times k$ design matrix, for $m$ observed points and $k$ basis funcitons, and $\widetilde q$ now the stacked vector of observations.
We can then place a complex normal prior $\theta \sim \mathcal{N}_{\mathbb{C}^k}(0, \tau^2 \hat\Xi)$ on the coeficient vector.
See e.g.\ \cite{Picinbono1996} for information on the complex normal distribution.
Here, $\lambda = \frac{\sigma^2}{\tau^2}$ is a hyperparameter controlling the strength of the penalisation.
\begin{equation}
  \argmax_{\theta \in \mathbb{C}^k} \,\, (\widetilde q - B\theta)^H (\widetilde q - B \theta) - \lambda {\theta}^H {\hat\Xi}^{-1} \theta
\end{equation}
The penalised estimate is then given by the solution to the above optimisation problem.
\begin{equation}
  \hat\theta = (B^H B + \lambda {\hat\Xi}^{-1})^{-1} B^H \widetilde q.
\end{equation}
The results of this smoothing procedure can be seen in \cref{fig:a-smooth-lm} for $\lambda = 0.4$.
%\begin{figure}
%  \centering
%  \begin{subfigure}{\textwidth}
%    \begin{subfigure}{0.48\textwidth}
%      \inputTikz{A-smooth-d3}
%    \end{subfigure}\hfill%
%    \begin{subfigure}{0.48\textwidth}
%      \inputTikz{A-smooth-sp}
%    \end{subfigure}
%    \caption{Centred elastic full Procrustes fits (grey) and smooth means (red).}
%    \label{fig:a-smooth-means-lm}
%  \end{subfigure}
%  \begin{subfigure}{\textwidth}
%    \centering
%    \begin{subfigure}{\textwidth}
%    \centering
%      \inputTikz{A-smooth-pfits-d3}
%    \end{subfigure}
%    \begin{subfigure}{\textwidth}
%    \centering
%      \inputTikz{A-smooth-pfits-sp}
%    \end{subfigure}
%    \caption{Smooth (red) and original (grey) observations.}
%    \label{fig:a-smooth-pfits-lm}
%  \end{subfigure}
%  \caption{Elastic full Procrustes means and fits for digits with smoothed observations ($\lambda = 1$). Parameters: Second order penalty and linear B-splines, with 13 equidistant knots. Data: See \cref{fig:41-digit3-means-b,fig:41-spiral-means-b}}
%  \label{fig:a-smooth}
%\end{figure}
\begin{figure}
  \centering
  \begin{subfigure}{\textwidth}
    \begin{subfigure}{0.48\textwidth}
      \inputTikz{A-smooth-d3-lamb}
    \end{subfigure}\hfill%
    \begin{subfigure}{0.48\textwidth}
      \inputTikz{A-smooth-sp-lamb}
    \end{subfigure}
    \caption{Centred elastic full Procrustes fits (grey) and smooth means (red).}
    \label{fig:a-smooth-means-lm}
  \end{subfigure}
  \begin{subfigure}{\textwidth}
    \centering
    \begin{subfigure}{\textwidth}
    \centering
      \inputTikz{A-smooth-pfits-d3-lamb}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
    \centering
      \inputTikz{A-smooth-pfits-sp-lamb}
    \end{subfigure}
    \caption{Smooth (red) and original (grey) observations.}
    \label{fig:a-smooth-pfits-lm}
  \end{subfigure}
  \caption{Elastic full Procrustes means and fits for digits with smoothed observations ($\lambda = 0.4$). Parameters: Second order penalty and linear B-splines, with 13 equidistant knots. Data: See \cref{fig:41-digit3-means-b,fig:41-spiral-means-b}}
  \label{fig:a-smooth-lm}
\end{figure}
The method succeeds in estimating very natural looking smooth SRV curves.
However, the smoothed curves tend to get shrinked towards the origin because of the ridge penalty.
This shrinking may be prevented by normalizing the smoothed SRV curve, leading to unit-length curves on original curve level.
In general, a normal prior is probably appropriate in this setting and a proper shape distribution, such as the complex Bingham distribution \parencite[see e.g.][Chap.\ 10]{DrydenMardia2016} should be used.
This can be seen when noting that we would ideally have a prior with $\mathbb{E}[\abs{\theta}] = \abs{\hat\theta_\mu}$, smoothing the observations towards a curve of similar size to the mean curve, which cannot be achieved with a normal distribution.
The smoothing could be further improved by providing true interpolation, so that the interpolated curve goes through the observed points on original curve level.
As the smoothed original curve is calculated by integrating the smoothed SRV curves, this means one has to implement a nonlinear constraint on SRV level, ensuring that the SRV curve integrates to the difference of the observed points on the interval between them.


\section{Implicit Rotation and Scaling Alignment}
\label{app:a-warp}
Instead of solving for the optimal warping and rotation and scaling alignment iteratively, we might optimse the warping alignment directly over the analytical solution to the rotation and scaling alignment (see \cref{lem:2-elfpdist}).
Then we have an alternative optimisation problem
\begin{align*}
  \gamma^\mathrm{opt} = & \argmin_{\gamma \in \Gamma}\, \sqrt{1 - \langle \widetilde q_1, (\widetilde q_2  \circ \gamma ) \sqrt{\dot\gamma} \rangle \langle (\widetilde q_2 \circ \gamma) \sqrt{\dot\gamma}, \widetilde q_1 \rangle } \\
    & \argmin_{\gamma \in \Gamma} \, \sqrt{1 - \langle (\widetilde q_2  \circ \gamma ) \sqrt{\dot\gamma}, \widetilde q_1 \rangle \langle \widetilde q_1, (\widetilde q_2 \circ \gamma) \sqrt{\dot\gamma} \rangle } \\
    = & \argmax_{\gamma \in \Gamma} \, \langle (\widetilde q_2  \circ \gamma ) \sqrt{\dot\gamma}, \widetilde q_1 \rangle \langle \widetilde q_1, (\widetilde q_2 \circ \gamma) \sqrt{\dot\gamma} \rangle \\
    = & \argmax_{\gamma \in \Gamma} \langle C_1 \, (\widetilde q_2 \circ \gamma ) \sqrt{\dot \gamma}, (\widetilde q_2 \circ \gamma)\sqrt{\dot\gamma} \rangle
\end{align*}
with $C_1$ the covariance operator belonging to the covariance function $C_1(s,t) = \widetilde q_1(s) \overline{\widetilde q_1 (t)}$ of $\widetilde q_1$ (compare also the derivation of the elastic full Procrustes mean).
In the mean estimation step, $C_1$ can be replaced with the estimated covariance surface, making the rotation and scaling alignment unneccessary and possibly providing a computational advantage.
However, this approach does not integrate with existing approaches for warping alignment such as \cite{Steyer2021}.
Further work might focus on solving the above optimisation problem for sparse and irregular planar curves.

%\section{Analysis of Tongue Shape Variability using Procrustes Residuals}
%\begin{itemize}
%  \item Want investiage how the effect of the flanking vowels \enquote*{aa} and \enquote*{ii} on tounge shape differs for the consonants 'd', 'l', 'n' and 's', while controlling for variability over six speakers and 5--7 repetitions of the same word per speaker.
%  \item Analysis should be invariant with respect to size, rotation, translation and parameterisation of the tounges.
%    This can e.g.\ account for anatomical differences between speakers, or inaccuracies in the measurement process.
%  \item \textbf{Idea:} Estimate a global mean function $q_0(t)$ from all curves and calculate the elastic full Procrustes residuals.
%    They are given by the difference of elastic full Procrustes fits and the mean function on SRV level
%    $$ \hat r_i = \left( \omega_i^\mathrm{opt} \cdot \widetilde q_i \circ \gamma_i^\mathrm{opt} \right) \sqrt{\dot\gamma_i^\mathrm{opt}} - \hat q_0 \,.$$
%    We can perform analysis over the $\hat r_i(t)$. 
%  \item A word is a combination of vowels and consonants $(C_v, C_c)$ with $C_v \in \{\mathrm{aa}, \mathrm{ii}\}$ and $C_c \in \{\mathrm{d},\mathrm{l},\mathrm{n},\mathrm{s}\}$, e.g.\ \enquote*{pada} corresponds to $(\mathrm{aa},\mathrm{d})$ as all words start with 'p'.
%    We can index each word--speaker pair $\left( C_v, C_c, C_s \right)$ by $k$, where $C_s \in \{1,\dots,6\}$ and $k = 1, \dots, K$ with $K = 2 \cdot 4 \cdot 6 = 48$.
%  \item Then we can gather the residuals $\hat r_{(k, rep_k)}(s_{(k,rep_k,j)})$ of the repetitions $rep_k$ (their number varies with $k$) of each word--speaker pair $k$, and estimate a \enquote*{mean} residual function for that word and speaker:
%    $$ \hat r_k (t) = \hat r_{\left( C_v, C_c, C_s \right)} (t) \approx \hat \theta_k^\top b(t)$$
%    Atm I use the mean basis here, which means linear B-Splines. Might be nicer to have something that is smoother.
%  \item We are interested in the effect of the flanking vowels on tounge shape given, for each consonant-speaker pair, by this difference:
%    $$ \hat d_{(C_c, C_s)}(t) = \hat r_{(\mathrm{aa}, C_c, C_s)} (t) - \hat r_{(\mathrm{ii}, C_c, C_s)} (t) = 
%      \left( \hat\theta^\top_{(\mathrm{aa}, C_c, C_s)} - \hat\theta^\top_{(\mathrm{aa}, C_c, C_s)} \right) b(t)\,. $$
%    Note that $\hat d(t) : [0,1] \rightarrow \mathbb{C}$ (two-dimensional)! The absolute differences over speakers and consonants are given by $\abs{\hat d_{(C_c, C_s)}(t)}$ are plotted in \cref{fig:4-diffs-vpn}.
%\end{itemize}
%\begin{figure}
%  \centering
%  \inputTikz{4-diffs-vpn}
%  \caption{a caption}
%  \label{fig:4-diffs-vpn}
%\end{figure}
%\begin{itemize}
%  \item Finally we can average the differences over each speaker as
%    $$ \hat d_{(C_c)} (t) = \left(\frac{1}{6} \sum_{C_s} \hat \theta^\top_{(C_c, C_s)} \right) b(t)$$
%    or likewise as absolute difference  $\abs{\hat d_{(C_c)}(t)}$ plotted in \cref{fig:4-diffs}.
%\end{itemize}
%\begin{figure}
%  \centering
%  \inputTikz{4-diffs}
%  \caption{Another caption}
%  \label{fig:4-diffs}
%\end{figure}
%\begin{itemize}
%  \item Man sieht, dass der Einfluss des flankierenden Vokals unabhängig vom Konsanten zu sein scheint.
%    Das ist zumindest ein anderes Ergebniss, als in dem Consulting Projekt.
%  \item Die Analysie ist hier auf SRV level.
%  \item Sofern das alles so Sinn macht, könnte man jetzt noch Konfidenzintervalle undsowas dazu berechnen.
%\end{itemize}
